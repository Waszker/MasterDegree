\lhead{\emph{Introduction}}
\chapter{Introduction}

\section{Aim of the work}

Study presented in this paper tries to combine few selected classifiers in such way that will empower them to gain rejection capabilities. The main goal is to come up with a model having a structure that allows it to reject patterns that are outside of native elements classes' scope without any prior knowledge about such patterns. Those outliers, denoted as foreign elements, are very common in real life situations when dealing with noisy, erroneous or unknown measurements. The main drawback of commonly used classifiers is their inability to reject foreign elements without any knowledge about them. Classifiers such as SVM, random forest or kNN (described better in Chapter \ref{common_classifiers}) must always classify presented pattern to one of the classes they were trained on. This  requirement to always classify provided pattern to one of the classes used during training process forces inclusion of foreign elements within training sets if there's a need to reject certain elements. Although not impossible, this approach is quite impractical as most of the time there are just too many possible cases of such elements. This paper tries to find a solution to this problem. \\

\section{Pattern recognition problem}

Pattern recognition is a branch of machine learning that focuses on the recognition of patterns and regularities in data. The problem of searching for patterns in data is a fundamental one and has a long and successful history. For instance, the extensive astronomical observations of Tycho Brahe in $16^{th}$ century allowed Johannes Kepler to discover the empirical laws of planetary motion. The field of pattern recognition is concerned with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take actions such as classifying the data into different categories.\cite{Bishop2006} \\

Deploying pattern recognition system starts with collecting and preprocessing data. For most practical applications it is often not sufficient to simply use raw data in the model as it can contain noisy or erroneous information. The input variables should first be preprocessed in order to transform them into some new space where, preferably, pattern recognition problem will be easier to solve. For instance, in the digit recognition problem, the images of the digits are typically translated and scaled so that each
digit is contained within a box of a fixed size. This preprocessing stage is also called feature extraction and might be also performed in order to speed up future computations. The aim is to find useful features that are fast to compute and which preserve some discriminatory information. Usually the size of the vector holding extracted features is smaller than the representation of initial raw data, which can be viewed as a form of dimensionality reduction. Care must be taken during preprocessing stage because reducing dimensionality can often lead to discarding or distortion of useful information. \\

The result of running the machine learning algorithm can be expressed as a function f(x) which takes input vector and generates response vector which can be used to retrieve class label assigned to the input. The precise form of this function is determined during training phase (sometimes called learning phase), on the basis of training data. After the model learns all data examples its ``knowledge`` is checked on the test data. The ability to categorize correctly new examples that differ from those used for training is known as generalization. Creation of training and test sets is often done by dividing initial preprocessed data into two smaller sets. The size of training to test set ratio is completely unrestricted, although in most practical cases 1:1 or 7:3 rates are preferred. Pattern recognition systems are in many cases trained from labelled training data, that means data that has class affiliation for each input vector already determined. Creating model on such data is called supervised learning. When no labelled data is available other algorithms can be used to discover previously unknown patterns, which is called unsupervised learning. The goal in such problems may be to discover groups of similar examples within the data, where it is called clustering, or to determine the distribution of data within the input space, also known as density estimation \\